{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Challenge: Feedback analysis",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zdwhite/Thinkful-Unit-2/blob/master/Challenge_Feedback_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jPkx2GCQnQ6_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re as re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WbEV47Kxor_6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Grab and process the raw data.\n",
        "data_path = (\"https://raw.githubusercontent.com/zdwhite/Thinkful-Unit-2/master/Sentiment%20Data%20Sets/yelp_labelled.txt\"\n",
        "            )\n",
        "sms_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
        "sms_raw.columns = ['message', 'sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iaYnejzpo8pD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sms_raw['message']=sms_raw['message'].str.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VirCKsa2pJRh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#before we tackle the NB model Let's get a sense of some key words\n",
        "\n",
        "#Split\n",
        "good_sentiment=sms_raw[sms_raw['sentiment']==1]['message'].apply(lambda x:x.split())\n",
        "\n",
        "#Looking through our bag of words, there are lots of punctuations and possibly special characters let's get rid of those\n",
        "good_sentiment = pd.DataFrame(good_sentiment).apply(lambda x: pd.Series(x['message']),axis=1).stack().reset_index(level=1, drop=True).reset_index()\n",
        "\n",
        "good_sentiment.columns=['Index','Words']\n",
        "\n",
        "good_sentiment['Words']=good_sentiment['Words'].apply(lambda x: re.sub('[^A-Za-z0-9]+','',x))\n",
        "\n",
        "GSWC = pd.DataFrame(good_sentiment['Words'].value_counts().reset_index())\n",
        "GSWC['sentiment']='Good'\n",
        "\n",
        "#Split\n",
        "bad_sentiment=sms_raw[sms_raw['sentiment']==0]['message'].apply(lambda x:x.split())\n",
        "\n",
        "bad_sentiment = pd.DataFrame(bad_sentiment).apply(lambda x: pd.Series(x['message']),axis=1).stack().reset_index(level=1, drop=True).reset_index()\n",
        "\n",
        "bad_sentiment.columns=['Index','Words']\n",
        "\n",
        "#Looking through our bag of words, there are lots of punctuations and possibly special characters let's get rid of those\n",
        "bad_sentiment['Words']=bad_sentiment['Words'].apply(lambda x: re.sub('[^A-Za-z0-9]+','',x))\n",
        "\n",
        "bad_sentiment['Words'].value_counts()\n",
        "\n",
        "BSWC = pd.DataFrame(bad_sentiment['Words'].value_counts().reset_index())\n",
        "BSWC['sentiment']='Bad'\n",
        "\n",
        "Bag_of_words=GSWC.append(BSWC)\n",
        "Bag_of_words.columns=['Word','Count','Sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zpGjpoT7Wjk2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5tfSVNQvcvoQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(figsize=(150, 30))\n",
        "ax.set_xticklabels(labels = Bag_of_words['Word'],rotation=90)\n",
        "ax = sns.barplot(x='Word',y='Count',hue='Sentiment',data=Bag_of_words[Bag_of_words['Count']>1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "srnF4yWkq_Rc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#for a word to be a keyword of bad sentiment let's assume that we choose all words that\n",
        "#appear greater in frequency as bad sentiment by at least 1 STD from the mean frequency of all words.\n",
        "#also we should pluck words that only appear in bad sentiment phrases\n",
        "\n",
        "#Summary Statistics\n",
        "Bag_of_words.describe()\n",
        "#std = Bag_of_words.describe()['Count'][2]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ZQpLSIKxDg-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Lets see if we need to normalize these two groups\n",
        "#It appears that they are very similar in mean and standard deviation so no we shouldn't worry about normalization\n",
        "\n",
        "\n",
        "print(Bag_of_words[Bag_of_words['Sentiment']=='Bad'].describe())\n",
        "\n",
        "print(Bag_of_words[Bag_of_words['Sentiment']=='Good'].describe())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ilOuSlZx6E4h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#pull list of keywords from Bag_of_Words\n",
        "\n",
        "  \n",
        "test = Bag_of_words[Bag_of_words[\"Sentiment\"] == \"Good\"].join(Bag_of_words[Bag_of_words[\"Sentiment\"] == \"Bad\"].set_index(\"Word\"), on = \"Word\", lsuffix=\"_Good\", rsuffix=\"_Bad\")\n",
        "\n",
        "test['Sentiment_Good'], test['Sentiment_Bad'] = 'Good', 'Bad'\n",
        "\n",
        "test = test.set_index('Word')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dPmeZe8YCzbd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "test.fillna(0,inplace=True)\n",
        "test\n",
        "\n",
        "#Bag_of_words.describe()\n",
        "std = Bag_of_words.describe()['Count'][2]\n",
        "\n",
        "keyword = []\n",
        "for word in test.index.values:\n",
        "  #print(test[test['Word']==word])\n",
        "  if test.loc[word][0] < test.loc[word][2]+std*2:\n",
        "    keyword.append(word)\n",
        "  if (test.loc[word][0]) == 0 & (test.loc[word][2] > 2):\n",
        "    if word not in keyword:\n",
        "      keyword.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DGI6fyRMEIph",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "keyword\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tfK28DenThZW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sms_raw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PMxQP-iKIjLM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# look for keywords with in the message\n",
        "for key in keyword:\n",
        "    # Note that we add spaces around the key so that we're getting the word,\n",
        "    # not just pattern matching.\n",
        "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
        "        ' ' + str(key) + ' ',\n",
        "        case=False\n",
        "    )\n",
        "    \n",
        "\n",
        "#Currently this throws an error because one of our keys contains a \")\", this is obviously annoying    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "snSCZZeVKVjp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Run this once it will return True if bad sentiment and False if good, \n",
        "sms_raw['sentiment'] = (sms_raw['sentiment'] == 0)\n",
        "\n",
        "sms_raw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "soAqb3_nKiD1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(figsize=(80, 80))\n",
        "ax.set_xticklabels(labels = test.index.values,rotation=90)\n",
        "ax = sns.heatmap(sms_raw.corr())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pRa8pyoaLxUz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#eliminating keys if we wanted  to filter the correlation matrix by keywords that correlate highly with one another\n",
        "\n",
        "cor_mat= pd.DataFrame(sms_raw.corr())\n",
        "thresh = .75\n",
        "\n",
        "cor_keywords = pd.DataFrame([],columns=['keyword','value','pair'])\n",
        "for key1 in cor_mat.index.values:\n",
        "  for key2 in cor_mat.index.values:\n",
        "    if key1 != key2:\n",
        "      if key1 not in cor_keywords['keyword']:\n",
        "        if cor_mat.loc[key1][key2]> thresh:\n",
        "          cor_keywords.loc[-1]= [key1,cor_mat.loc[key1][key2],key2]\n",
        "          cor_keywords.index = cor_keywords.index+1\n",
        "          \n",
        "  \n",
        "cor_keywords=cor_keywords.sort_index()\n",
        "#cor_mat.loc['sentiment']['sentiment']\n",
        "cor_keywords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DcQIDo4cPp1W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After cleaning up a lot of our data with regular expression and case sensitivity we start to see some of the words that correlate fairly highly to one another."
      ]
    },
    {
      "metadata": {
        "id": "kMqm3KtrPQ-1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sms_raw\n",
        "\n",
        "data = sms_raw[keyword]\n",
        "target = sms_raw['sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "icA86NN1QyWz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d1e39e31-7162-4021-c5af-e18e55e769eb"
      },
      "cell_type": "code",
      "source": [
        "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "# Instantiate our model and store it in a new variable.\n",
        "bnb = BernoulliNB()\n",
        "\n",
        "# Fit our model to the data.\n",
        "bnb.fit(data, target)\n",
        "\n",
        "# Classify, storing the result in a new variable.\n",
        "y_pred = bnb.predict(data)\n",
        "\n",
        "# Display our results.\n",
        "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
        "    data.shape[0],\n",
        "    (target != y_pred).sum()\n",
        "))"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of mislabeled points out of a total 1000 points : 180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y6uG965hQ1Jj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First pass shows us mislabeling  180 out of 1000, not too shabby.\n",
        "\n",
        "Lets try and detect good sentiment instead and see if there is a difference"
      ]
    },
    {
      "metadata": {
        "id": "SJrx1O-6dYeO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_path = (\"https://raw.githubusercontent.com/zdwhite/Thinkful-Unit-2/master/Sentiment%20Data%20Sets/yelp_labelled.txt\"\n",
        "            )\n",
        "sms_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
        "sms_raw.columns = ['message', 'sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6VRjOhTJdbW7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sms_raw['message']=sms_raw['message'].str.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q26olxUJRGIg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test.fillna(0,inplace=True)\n",
        "test\n",
        "\n",
        "#Bag_of_words.describe()\n",
        "std = Bag_of_words.describe()['Count'][2]\n",
        "\n",
        "keyword = []\n",
        "for word in test.index.values:\n",
        "  #print(test[test['Word']==word])\n",
        "  if test.loc[word][0]+std > test.loc[word][2]:\n",
        "    keyword.append(word)\n",
        "  if (test.loc[word][0]) >= 1 & (test.loc[word][2] == 0):\n",
        "    if word not in keyword:\n",
        "      keyword.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lb_zCjkpSwte",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for key in keyword:\n",
        "    # Note that we add spaces around the key so that we're getting the word,\n",
        "    # not just pattern matching.\n",
        "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
        "        ' ' + str(key) + ' ',\n",
        "        case=False\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HPrv8AnsdoWM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Run this once it will return True if bad sentiment and False if good, \n",
        "\n",
        "\n",
        "sms_raw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-fFwpyB1dwQH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sms_raw\n",
        "\n",
        "data = sms_raw[keyword]\n",
        "target = sms_raw['sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MS4kRC28droX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ab761b23-9ef0-4b75-d140-128b3c927b53"
      },
      "cell_type": "code",
      "source": [
        "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "# Instantiate our model and store it in a new variable.\n",
        "bnb = BernoulliNB()\n",
        "\n",
        "# Fit our model to the data.\n",
        "bnb.fit(data, target)\n",
        "\n",
        "# Classify, storing the result in a new variable.\n",
        "y_pred = bnb.predict(data)\n",
        "\n",
        "# Display our results.\n",
        "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
        "    data.shape[0],\n",
        "    (target != y_pred).sum()\n",
        "))"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of mislabeled points out of a total 1000 points : 163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sj4TuE85g66-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We were able to squeeze just a little more accuracy out of our model using good sentiment detection versus.\n",
        "\n",
        "Let's see how it works with a new data set."
      ]
    },
    {
      "metadata": {
        "id": "DPcxBsBPhJdx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "data_path = (\"https://raw.githubusercontent.com/zdwhite/Thinkful-Unit-2/master/Sentiment%20Data%20Sets/imdb_labelled.txt\"\n",
        "            )\n",
        "sms_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
        "sms_raw.columns = ['message', 'sentiment']\n",
        "\n",
        "sms_raw['message']=sms_raw['message'].str.lower()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OTUxPc7qhog3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for key in keyword:\n",
        "    # Note that we add spaces around the key so that we're getting the word,\n",
        "    # not just pattern matching.\n",
        "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
        "        ' ' + str(key) + ' ',\n",
        "        case=False\n",
        "    )\n",
        "    \n",
        "sms_raw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oSbO0Xwchsqn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sms_raw['sentiment'] = (sms_raw['sentiment'] != 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BZTEzuD1hyJW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#keep the same good sentiment keywords as befor\n",
        "\n",
        "data = sms_raw[keyword]\n",
        "target = sms_raw['sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZjayzI-lh6pt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2256e44e-20d6-430b-b818-5c14c6102248"
      },
      "cell_type": "code",
      "source": [
        "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "# Instantiate our model and store it in a new variable.\n",
        "bnb = BernoulliNB()\n",
        "\n",
        "# Fit our model to the data.\n",
        "bnb.fit(data, target)\n",
        "\n",
        "# Classify, storing the result in a new variable.\n",
        "y_pred = bnb.predict(data)\n",
        "\n",
        "# Display our results.\n",
        "print(\"Number of mislabeled points out of a total {} points : {}, {}% inaccuracy rate\".format(\n",
        "    data.shape[0],\n",
        "    (target != y_pred).sum(),\n",
        "    round(((target != y_pred).sum()/data.shape[0])*100,2)\n",
        "))"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of mislabeled points out of a total 748 points : 157, 20.99% inaccuracy rate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4KKRSpkuh8f1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our keywords from the yelp data set was able to correctly identify 79% of good sentitment IMDB ratings."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xrRg-dwdCTHT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#let's check that last dataset and see how it performs \n",
        "\n",
        "#if i wasn't lazy i'd just make a function out of all of this and pass the dataset through for the results\n",
        "\n",
        "\n",
        "data_path = (\"https://raw.githubusercontent.com/zdwhite/Thinkful-Unit-2/master/Sentiment%20Data%20Sets/amazon_cells_labelled.txt\"\n",
        "            )\n",
        "sms_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
        "sms_raw.columns = ['message', 'sentiment']\n",
        "\n",
        "sms_raw['message']=sms_raw['message'].str.lower()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4QrPFaE8CTHX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for key in keyword:\n",
        "    # Note that we add spaces around the key so that we're getting the word,\n",
        "    # not just pattern matching.\n",
        "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
        "        ' ' + str(key) + ' ',\n",
        "        case=False\n",
        "    )\n",
        "    \n",
        "sms_raw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wv-Tr2wJCTHY",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sms_raw['sentiment'] = (sms_raw['sentiment'] != 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "k3XNYs0UCTHb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#keep the same good sentiment keywords as befor\n",
        "\n",
        "data = sms_raw[keyword]\n",
        "target = sms_raw['sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "a014d57a-e88c-47dd-bf8a-4da3dbf33146",
        "id": "rOE6WIWUCTHd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "# Instantiate our model and store it in a new variable.\n",
        "bnb = BernoulliNB()\n",
        "\n",
        "# Fit our model to the data.\n",
        "bnb.fit(data, target)\n",
        "\n",
        "# Classify, storing the result in a new variable.\n",
        "y_pred = bnb.predict(data)\n",
        "\n",
        "# Display our results.\n",
        "print(\"Number of mislabeled points out of a total {} points : {}, {}% inaccuracy rate\".format(\n",
        "    data.shape[0],\n",
        "    (target != y_pred).sum(),\n",
        "    round(((target != y_pred).sum()/data.shape[0])*100,2)\n",
        "))"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of mislabeled points out of a total 1000 points : 225, 22.5% inaccuracy rate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Pw75tBGQ1nUk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#What are the messages that are miss_labled and is there anything about them that is special.\n",
        "miss_labeled = np.where(y_pred !=  target)[0]\n",
        "\n",
        "miss_labeled\n",
        "\n",
        "sms_raw.iloc[miss_labeled,:]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}